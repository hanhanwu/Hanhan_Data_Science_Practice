# A/B Tets

ðŸŒº The main purpose for A/B test is to use the data we collect from variants A and B, computing some metrics for each variant, then with statistical methods to determine which variant is better.

## Frequentist Methods
* [My Code - Practical A/B Test Experiments][1]
* Using p-value to choose hypothesis
  * Null Hypothesis - There's no difference between variant A, B
  * Alternative Hypothesis - A, B are different
* "A p-value measures the probability of observing a difference between the two variants at least as extreme as what we actually observed, given that there is no difference between the variants."
  * Only after p-value achieves statistical significance or we have seen enough data, the experiment ends.
* <b>Drawbacks</b>
  * Have to know how much data needed. Cannot test in real time, but need to wait till getting planned data size.
  * It's hard to know what to do when it's not statistically significant, or you don't have enough data. Not sure what to do when the new solution is slightly better than the old solution.

## Bayesian A/B Test
* In Bayesian A/B testing, we model the metric for each variant as a random variable with some probability distribution. 
* After observing data from both variants, we update our prior beliefs about the most likely values for each variant.
* Comparing with Frequentist Method, Bayesian method tend to accept variants that offer slight improvement. Bayesian A/B testing asserts that the false positive rate (the proportion of times we accept the solution when the it's not really better) is not very important. Instead, Bayesian A/B testing focuses on the average magnitude of wrong decisions over the course of many experiments.
* In a word, Bayesian A/B test tends to guaratee the long term improvement on a metric, by limiting the amount of wrong decisions that can make the products worse.
* For industries that did lots of experiments, they might have enough priori distributions to use, this could help reach to the conclusion faster with less data.
  * But when choosing the priori, better to choose a weaker distribution then the historical observations suggested.
  * Bayesian A/B test reaches to the conclusion faster than other methods
* Drawbacks:
  * Difficult to explain the concept of expected loss to business audience.

* References
  * https://medium.com/convoy-tech/the-power-of-bayesian-a-b-testing-f859d2219d5
  * https://blog.exploratory.io/an-introduction-to-bayesian-a-b-testing-in-exploratory-cb5a7ad80963
* R - `bayesAB`
  * R package: https://github.com/FrankPortman/bayesAB


[1]:https://github.com/hanhanwu/Hanhan_Data_Science_Practice/tree/master/Applied_Statistics/ABTest_Experiments
